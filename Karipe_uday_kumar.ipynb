{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sISWtYEcWwZd",
        "outputId": "44f1787b-bd86-4f01-9f56-6d231b535dc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycrf\n",
            "  Downloading pycrf-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycrf\n",
            "  Building wheel for pycrf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycrf: filename=pycrf-0.0.1-py3-none-any.whl size=1896 sha256=ad7fd5a14ed835093f5c81bbf7012fd75f4af3742ce0e8a9472b1878faa8d340\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/bf/ca/6777c01db8f2183ae7c5fadfc62d6e88d3e6d600c6379fa3c9\n",
            "Successfully built pycrf\n",
            "Installing collected packages: pycrf\n",
            "Successfully installed pycrf-0.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "  Downloading python_crfsuite-0.9.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (4.64.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from sklearn-crfsuite) (0.8.10)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9 sklearn-crfsuite-0.3.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "!pip install pycrf\n",
        "!pip install sklearn-crfsuite\n",
        "\n",
        "import spacy\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "\n",
        "model = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Torq17fDWxc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VSo4rQiW1R0",
        "outputId": "0779f239-4cf1-4a65-9e05-04428c4efd80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_inputfile(input_file):\n",
        "    i_file = open(input_file, 'r')\n",
        "    file_name = i_file.readlines()\n",
        "    i_file.close()\n",
        "\n",
        "    output_list = []\n",
        "\n",
        "    full_sentence = \"\"\n",
        "\n",
        "    for each_word in file_name:\n",
        "        each_word = each_word.strip()\n",
        "        if each_word == \"\":\n",
        "            output_list.append(full_sentence) \n",
        "            full_sentence = \"\" \n",
        "        else:\n",
        "            if full_sentence:\n",
        "                full_sentence += \" \" + each_word\n",
        "            else:\n",
        "                full_sentence = each_word\n",
        "                \n",
        "    return output_list"
      ],
      "metadata": {
        "id": "6X2jxsenW4L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = preprocess_inputfile('/content/gdrive/MyDrive/train_sent')\n",
        "train_labels = preprocess_inputfile('/content/gdrive/MyDrive/train_label')\n",
        "test_sentences = preprocess_inputfile('/content/gdrive/MyDrive/test_sent')\n",
        "test_labels = preprocess_inputfile('/content/gdrive/MyDrive/test_label')"
      ],
      "metadata": {
        "id": "0bAzaYWgXA4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for each_item in range(5):\n",
        "    print(f\"Sentence {each_item+1} is: {train_sentences[each_item]}\")\n",
        "    print(f\"Label {each_item+1} is: {train_labels[each_item]}\")\n",
        "    print(\"*\"*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLg-w26RXEiB",
        "outputId": "6be2c5ee-1cb3-4b4f-82b5-986606d11b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1 is: All live births > or = 23 weeks at the University of Vermont in 1995 ( n = 2395 ) were retrospectively analyzed for delivery route , indication for cesarean , gestational age , parity , and practice group ( to reflect risk status )\n",
            "Label 1 is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 2 is: The total cesarean rate was 14.4 % ( 344 of 2395 ) , and the primary rate was 11.4 % ( 244 of 2144 )\n",
            "Label 2 is: O O O O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 3 is: Abnormal presentation was the most common indication ( 25.6 % , 88 of 344 )\n",
            "Label 3 is: O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 4 is: The `` corrected '' cesarean rate ( maternal-fetal medicine and transported patients excluded ) was 12.4 % ( 273 of 2194 ) , and the `` corrected '' primary rate was 9.6 % ( 190 of 1975 )\n",
            "Label 4 is: O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n",
            "Sentence 5 is: Arrest of dilation was the most common indication in both `` corrected '' subgroups ( 23.4 and 24.6 % , respectively )\n",
            "Label 5 is: O O O O O O O O O O O O O O O O O O O O O O\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of sentences in processed train dataset is: {len(train_sentences)}\")\n",
        "print(f\"Number of sentences in processed test dataset is: {len(test_sentences)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNQePYPDXIch",
        "outputId": "f44c5d22-06c4-49ef-d977-55f03527cf72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in processed train dataset is: 2599\n",
            "Number of sentences in processed test dataset is: 1056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of lines of labels in processed train dataset is: {len(train_labels)}\")\n",
        "print(f\"Number of lines of labels in processed test dataset is: {len(test_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbVgt6ffXMZG",
        "outputId": "b3f7625d-c26f-46c5-8995-35c27c8b1181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of lines of labels in processed train dataset is: 2599\n",
            "Number of lines of labels in processed test dataset is: 1056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noun_propn_tokens_list = []"
      ],
      "metadata": {
        "id": "VVdoaZkWXQTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentences in (train_sentences, test_sentences):\n",
        "    for sent in sentences:\n",
        "        processed_sent = model(sent)\n",
        "        for each_token in processed_sent:\n",
        "            if each_token.pos_ == \"NOUN\" or each_token.pos_ == \"PROPN\":\n",
        "                noun_propn_tokens_list.append(each_token.text)"
      ],
      "metadata": {
        "id": "3olxERABXTvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_noun_propn = pd.Series(noun_propn_tokens_list)"
      ],
      "metadata": {
        "id": "sw5hbmF1XWlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_noun_propn.value_counts().sort_values(ascending=False).head(25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtDafBxOXaFe",
        "outputId": "8af3f6b9-92c6-4d3e-cddc-57a2095c1127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "patients        492\n",
              "treatment       281\n",
              "%               247\n",
              "cancer          200\n",
              "therapy         175\n",
              "study           154\n",
              "disease         142\n",
              "cell            140\n",
              "lung            116\n",
              "group            94\n",
              "chemotherapy     88\n",
              "gene             87\n",
              "effects          85\n",
              "women            77\n",
              "results          77\n",
              "use              75\n",
              "surgery          71\n",
              "risk             71\n",
              "cases            71\n",
              "analysis         70\n",
              "rate             67\n",
              "response         66\n",
              "dose             66\n",
              "survival         65\n",
              "children         64\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFeaturesForOneWord(sentence, pos, pos_tags):\n",
        "  word = sentence[pos]\n",
        "\n",
        "  features = [\n",
        "    'word.lower=' + word.lower(), \n",
        "    'word[-3:]=' + word[-3:],     \n",
        "    'word[-2:]=' + word[-2:],     \n",
        "    'word.isupper=%s' % word.isupper(),  \n",
        "    'word.isdigit=%s' % word.isdigit(),  \n",
        "    'word.startsWithCapital=%s' % word[0].isupper(), \n",
        "    'word.pos=' + pos_tags[pos]\n",
        "  ]\n",
        "\n",
        " \n",
        "  if(pos > 0):\n",
        "    prev_word = sentence[pos-1]\n",
        "    features.extend([\n",
        "    'prev_word.lower=' + prev_word.lower(), \n",
        "    'prev_word.isupper=%s' % prev_word.isupper(),\n",
        "    'prev_word.isdigit=%s' % prev_word.isdigit(),\n",
        "    'prev_word.startsWithCapital=%s' % prev_word[0].isupper(),\n",
        "    'prev_word.pos=' + pos_tags[pos-1]\n",
        "  ])\n",
        " \n",
        "  else:\n",
        "    features.append('BEG') \n",
        "    \n",
        "  if(pos == len(sentence)-1):\n",
        "    features.append('END') \n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "r_Egg-luXdKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFeaturesForOneSentence(sentence):\n",
        "    \n",
        "    # We need to get the pos_tags to be passed to the function\n",
        "    processed_sent = model(sentence)\n",
        "    postags = []\n",
        "    \n",
        "    for each_token in processed_sent:\n",
        "        postags.append(each_token.pos_)\n",
        "    \n",
        "    sentence_list = sentence.split()\n",
        "    return [getFeaturesForOneWord(sentence_list, pos, postags) for pos in range(len(sentence_list))]"
      ],
      "metadata": {
        "id": "GKHf_0Q_XlNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLabelsInListForOneSentence(labels):\n",
        "  return labels.split()"
      ],
      "metadata": {
        "id": "1BtQjTWxXonW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [getFeaturesForOneSentence(sentence) for sentence in train_sentences]\n",
        "X_test = [getFeaturesForOneSentence(sentence) for sentence in test_sentences]"
      ],
      "metadata": {
        "id": "s4LgfqckXrSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = [getLabelsInListForOneSentence(labels) for labels in train_labels]\n",
        "Y_test = [getLabelsInListForOneSentence(labels) for labels in test_labels]"
      ],
      "metadata": {
        "id": "gaCAbADNXtoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn_crfsuite\n",
        "\n",
        "from sklearn_crfsuite import metrics"
      ],
      "metadata": {
        "id": "aif4hLLFXwE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crf = sklearn_crfsuite.CRF(max_iterations=100)"
      ],
      "metadata": {
        "id": "ndNK-2xwXyel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    crf.fit(X_train, Y_train)\n",
        "except AttributeError:\n",
        "    pass\n",
        "predictions = crf.predict(X_test)"
      ],
      "metadata": {
        "id": "zt0OOXntYZEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = crf.predict(X_test)"
      ],
      "metadata": {
        "id": "2KrcAS85YhuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = metrics.flat_f1_score(Y_test, Y_pred, average='weighted')\n",
        "print(f\"F1 score is: {round(f1_score,4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbYvdH1WYo2E",
        "outputId": "1b43e4e8-6a11-426c-ac48-cd6b00fd5e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score is: 0.9058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_T_dict = dict()\n",
        "\n",
        "for i in range(len(Y_pred)):\n",
        "    # Get the predicted labels of each test sentence into \"val\"\n",
        "    val = Y_pred[i]\n",
        "    \n",
        "    # Empty strings to store the values of Diseases and Treatments\n",
        "    Diseases = \"\"\n",
        "    Treatments = \"\"\n",
        "    \n",
        "    # Each loop will iterate through the individual labels and focus on mapping D and T labels\n",
        "    # with Diseases and Treatments within each sentence into a concatenated string\n",
        "    for j in range(len(val)):\n",
        "        if val[j] == 'D': # If label is D, it indicates a Disease \n",
        "            Diseases += test_sentences[i].split()[j] + \" \"\n",
        "        elif val[j] == 'T': # If label is T, it indicates a Treatment\n",
        "            Treatments += test_sentences[i].split()[j] + \" \"\n",
        "            \n",
        "    # Removes any extra whitespaces to either end of the string\n",
        "    Diseases = Diseases.lstrip().rstrip()\n",
        "    Treatments = Treatments.lstrip().rstrip()\n",
        "\n",
        "    # If Diseases and Treatments are blank, ignore them\n",
        "    # If Disease is not present in Dictionary, add it along with the corresponding treatment\n",
        "    # If Disease is present in the Dictionary, append the treatments for that diseases with existing\n",
        "    # treatments\n",
        "    if Diseases != \"\" and Treatments != \"\":\n",
        "        if Diseases in D_T_dict.keys():\n",
        "            treat_out = list(D_T_dict[Diseases])\n",
        "            treat_out.append(Treatments)\n",
        "            D_T_dict[Diseases] = treat_out\n",
        "        elif Diseases not in D_T_dict.keys():\n",
        "            D_T_dict[Diseases] = Treatments"
      ],
      "metadata": {
        "id": "2iCZ6FXLYtLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_T_dict['hereditary retinoblastoma']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xxMAx6mvYzYP",
        "outputId": "bdc40269-7cd9-45dd-93f4-26469b98fade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'radiotherapy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lZiGk_sFY1_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}